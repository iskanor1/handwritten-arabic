{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iskanor1/handwritten-arabic-/blob/main/Handwritten%20Arabic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Welcome To Colab\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/notebooks/intro.ipynb\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# Configuration\n",
        "# ----------------------------------------------------------------------\n",
        "IMAGE_DATA_PATH_TRAIN = '/content/csvTrainImages 13440x1024.csv'\n",
        "LABEL_DATA_PATH_TRAIN = '/content/csvTrainLabel 13440x1.csv'\n",
        "IMAGE_DATA_PATH_TEST = '/content/csvTestImages 3360x1024.csv'\n",
        "LABEL_DATA_PATH_TEST = '/content/csvTestLabel 3360x1.csv'\n",
        "\n",
        "TF_EPOCHS = 20  # Adjusted epochs for potentially faster convergence\n",
        "TF_BATCH_SIZE = 64\n",
        "RANDOM_SEED = 42\n",
        "VALIDATION_SIZE = 0.2  # Fraction of training data to use for validation\n",
        "IMAGE_WIDTH = 32\n",
        "IMAGE_HEIGHT = 32\n",
        "NUM_CHANNELS = 1\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 1. Load Data from CSV\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def load_data_from_csv(file_path, is_label=False):\n",
        "    \"\"\"Loads data from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "        is_label (bool): If True, reshapes the output to a 1D array for labels.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Data as a NumPy array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, header=None)\n",
        "        data = df.values.astype('float32')\n",
        "        if not is_label:\n",
        "            data = data.reshape(-1, IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS) / 255.0  # Normalize and reshape for CNN\n",
        "        else:\n",
        "            data = data.flatten()\n",
        "        return data\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "        return None\n",
        "\n",
        "# Load the data\n",
        "X_train_full = load_data_from_csv(IMAGE_DATA_PATH_TRAIN)\n",
        "y_train_full = load_data_from_csv(LABEL_DATA_PATH_TRAIN, is_label=True)\n",
        "X_test = load_data_from_csv(IMAGE_DATA_PATH_TEST)\n",
        "y_test = load_data_from_csv(LABEL_DATA_PATH_TEST, is_label=True)\n",
        "\n",
        "if X_train_full is None or y_train_full is None or X_test is None or y_test is None:\n",
        "    exit()\n",
        "\n",
        "# Split training data into training and validation sets for TensorFlow\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=VALIDATION_SIZE, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# Determine the number of classes\n",
        "num_classes = int(np.max(y_train_full)) + 1\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# 2. TensorFlow/Keras Implementation (CNN)\n",
        "# ----------------------------------------------------------------------\n",
        "def create_tf_cnn_model(input_shape, num_classes):\n",
        "    \"\"\"Creates a TensorFlow/Keras CNN model.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): Shape of the input images (height, width, channels).\n",
        "        num_classes (int): Number of classes.\n",
        "\n",
        "    Returns:\n",
        "        tensorflow.keras.models.Sequential: A TensorFlow/Keras CNN model.\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, name='conv2d_1'),\n",
        "        layers.MaxPooling2D((2, 2), name='max_pooling2d_1'),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', name='conv2d_2'),\n",
        "        layers.MaxPooling2D((2, 2), name='max_pooling2d_2'),\n",
        "        layers.Flatten(name='flatten'),\n",
        "        layers.Dense(128, activation='relu', name='dense_1'),\n",
        "        layers.Dropout(0.5, name='dropout_1'),\n",
        "        layers.Dense(num_classes, activation='softmax', name='output')\n",
        "    ], name=\"tf_cnn_model\")\n",
        "    return model\n",
        "\n",
        "def train_tf_cnn_model(model, X_train, y_train, X_val, y_val, num_classes, epochs=TF_EPOCHS, batch_size=TF_BATCH_SIZE):\n",
        "    \"\"\"Trains a TensorFlow/Keras CNN model.\n",
        "\n",
        "    Args:\n",
        "        model (tensorflow.keras.models.Sequential): The model to train.\n",
        "        X_train (numpy.ndarray): Training image data.\n",
        "        y_train (numpy.ndarray): Training labels.\n",
        "        X_val (numpy.ndarray): Validation image data.\n",
        "        y_val (numpy.ndarray): Validation labels.\n",
        "        num_classes (int): Number of classes.\n",
        "        epochs (int): Number of training epochs (default: TF_EPOCHS).\n",
        "        batch_size (int): Batch size (default: TF_BATCH_SIZE).\n",
        "\n",
        "    Returns:\n",
        "        tensorflow.keras.callbacks.History: Training history.\n",
        "    \"\"\"\n",
        "    # One-hot encode the labels for tensorflow\n",
        "    y_train_encoded = to_categorical(y_train, num_classes=num_classes)\n",
        "    y_val_encoded = to_categorical(y_val, num_classes=num_classes)\n",
        "    y_test_encoded = to_categorical(y_test, num_classes=num_classes) # Encode test labels as well\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    history = model.fit(X_train, y_train_encoded, epochs=epochs, batch_size=batch_size,\n",
        "                        validation_data=(X_val, y_val_encoded), verbose=1)\n",
        "    return history\n",
        "\n",
        "def evaluate_tf_cnn_model(model, X_test, y_test, num_classes):\n",
        "    \"\"\"Evaluates a TensorFlow/Keras CNN model.\n",
        "\n",
        "    Args:\n",
        "        model (tensorflow.keras.models.Sequential): The model to evaluate.\n",
        "        X_test (numpy.ndarray): Test image data.\n",
        "        y_test (numpy.ndarray): Test labels.\n",
        "        num_classes (int): Number of classes.\n",
        "\n",
        "    Returns:\n",
        "        float: Test accuracy.\n",
        "    \"\"\"\n",
        "    y_test_encoded = to_categorical(y_test, num_classes=num_classes)\n",
        "    loss, accuracy = model.evaluate(X_test, y_test_encoded, verbose=0)\n",
        "    print(f'TensorFlow/Keras CNN Test Accuracy: {accuracy:.4f}')\n",
        "    return accuracy\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    input_shape_tf = (IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS)\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # TensorFlow/Keras (CNN)\n",
        "    # ----------------------------------------------------------------------\n",
        "    tf_cnn_model = create_tf_cnn_model(input_shape_tf, num_classes)\n",
        "    tf_cnn_history = train_tf_cnn_model(tf_cnn_model, X_train, y_train, X_val, y_val, num_classes)\n",
        "    tf_cnn_accuracy = evaluate_tf_cnn_model(tf_cnn_model, X_test, y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DZ8pbusr6zUb",
        "outputId": "56004902-e4cc-4b52-9d78-e114c127d491"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"tf_cnn_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"tf_cnn_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m295,040\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │         \u001b[38;5;34m3,741\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,040</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,741</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m317,597\u001b[0m (1.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">317,597</span> (1.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m317,597\u001b[0m (1.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">317,597</span> (1.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.1508 - loss: 2.9046 - val_accuracy: 0.5733 - val_loss: 1.4344\n",
            "Epoch 2/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4880 - loss: 1.5877 - val_accuracy: 0.7277 - val_loss: 0.8923\n",
            "Epoch 3/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6360 - loss: 1.0919 - val_accuracy: 0.8155 - val_loss: 0.6300\n",
            "Epoch 4/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7186 - loss: 0.8492 - val_accuracy: 0.8270 - val_loss: 0.5514\n",
            "Epoch 5/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7598 - loss: 0.7207 - val_accuracy: 0.8609 - val_loss: 0.4460\n",
            "Epoch 6/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.6108 - val_accuracy: 0.8817 - val_loss: 0.3797\n",
            "Epoch 7/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8248 - loss: 0.5404 - val_accuracy: 0.8888 - val_loss: 0.3426\n",
            "Epoch 8/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8390 - loss: 0.4771 - val_accuracy: 0.8850 - val_loss: 0.3416\n",
            "Epoch 9/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 0.4430 - val_accuracy: 0.9036 - val_loss: 0.2963\n",
            "Epoch 10/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8704 - loss: 0.3909 - val_accuracy: 0.9062 - val_loss: 0.2898\n",
            "Epoch 11/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8801 - loss: 0.3587 - val_accuracy: 0.9070 - val_loss: 0.2718\n",
            "Epoch 12/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8879 - loss: 0.3224 - val_accuracy: 0.9163 - val_loss: 0.2529\n",
            "Epoch 13/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8947 - loss: 0.3066 - val_accuracy: 0.9196 - val_loss: 0.2481\n",
            "Epoch 14/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9015 - loss: 0.2829 - val_accuracy: 0.9115 - val_loss: 0.2603\n",
            "Epoch 15/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.2619 - val_accuracy: 0.9237 - val_loss: 0.2447\n",
            "Epoch 16/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9129 - loss: 0.2380 - val_accuracy: 0.9237 - val_loss: 0.2358\n",
            "Epoch 17/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9218 - loss: 0.2237 - val_accuracy: 0.9237 - val_loss: 0.2486\n",
            "Epoch 18/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 0.2184 - val_accuracy: 0.9249 - val_loss: 0.2385\n",
            "Epoch 19/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9247 - loss: 0.2128 - val_accuracy: 0.9133 - val_loss: 0.2684\n",
            "Epoch 20/20\n",
            "\u001b[1m168/168\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9325 - loss: 0.1978 - val_accuracy: 0.9256 - val_loss: 0.2437\n",
            "TensorFlow/Keras CNN Test Accuracy: 0.9229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def preprocess_image_for_model(img_path, target_size=(32, 32)):\n",
        "    \"\"\"\n",
        "    Preprocesses a single image for use with a TensorFlow model that expects\n",
        "    flattened input.  This includes loading, resizing, normalizing, and flattening.\n",
        "\n",
        "    Args:\n",
        "        img_path (str): Path to the image file.\n",
        "        target_size (tuple, optional): The size to resize the image to (height, width).\n",
        "            Defaults to (32, 32).  This should match the size of images\n",
        "            your model was trained on.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: A flattened NumPy array representing the preprocessed image,\n",
        "                         or None if there's an error.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Load the image\n",
        "        img = image.load_img(img_path, target_size=target_size)\n",
        "\n",
        "        # 2. Convert to a NumPy array\n",
        "        img_array = image.img_to_array(img)\n",
        "\n",
        "        # 3. Expand dimensions to create a batch of size 1\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "        # 4. Normalize the pixel values (important for most models)\n",
        "        img_array = img_array / 255.0\n",
        "\n",
        "        # 5. Flatten the image\n",
        "        flattened_img = img_array.flatten()\n",
        "\n",
        "        return flattened_img\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Image not found at {img_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing the image: {e}\")\n",
        "        return None\n",
        "\n",
        "def test_model_with_image(model, img_path, target_size=(32, 32)):\n",
        "    \"\"\"\n",
        "    Loads an image, preprocesses it, and uses a TensorFlow model to make a prediction.\n",
        "\n",
        "    Args:\n",
        "        model (tensorflow.keras.Model): Your trained TensorFlow model.\n",
        "        img_path (str): Path to the image file.\n",
        "        target_size (tuple, optional): The size to resize the image to.\n",
        "            Defaults to (32, 32).\n",
        "    \"\"\"\n",
        "    flattened_image = preprocess_image_for_model(img_path, target_size)\n",
        "    if flattened_image is None:\n",
        "        print(\"Error: Image preprocessing failed.\")\n",
        "        return\n",
        "\n",
        "    # важно!!! Reshape the flattened image to match the input shape the model expects.\n",
        "    # The model was trained on flattened images of a certain dimension.\n",
        "    input_shape = model.input_shape\n",
        "    # Remove the batch dimension (None) and get the expected number of features\n",
        "    expected_features = input_shape[1]  # Get size after flattening\n",
        "    reshaped_image = flattened_image.reshape(1, expected_features) # Add batch dimension\n",
        "\n",
        "    # 6. Make a prediction\n",
        "    predictions = model.predict(reshaped_image)\n",
        "\n",
        "    # Process the predictions (this will depend on your model's output)\n",
        "    # For example, if it's a classification model:\n",
        "    class_index = np.argmax(predictions[0])  # Get the index of the highest probability\n",
        "    print(f\"Raw Predictions: {predictions}\")\n",
        "    print(f\"Predicted class index: {class_index}\")\n",
        "    return predictions # Return the raw predictions\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to demonstrate the image preprocessing and testing process.\n",
        "    \"\"\"\n",
        "    # 1. Load your trained TensorFlow model\n",
        "    # Replace 'your_model.h5' with the actual path to your saved model file\n",
        "    try:\n",
        "        model = tf.keras.models.load_model('your_model.h5')\n",
        "    except Exception as e:\n",
        "        print(f\"Error: Failed to load model: {e}\")\n",
        "        return\n",
        "\n",
        "    # 2. Specify the path to the image you want to test\n",
        "    image_path = '/content/Untitled.png'  # Replace with a valid image path\n",
        "\n",
        "    # 3. Call the function to test the image\n",
        "    predictions = test_model_with_image(model, image_path)\n",
        "    if predictions is not None:\n",
        "       print(\"Successfully made predictions\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRPeVZaQ8Gyz",
        "outputId": "bc508f19-cad6-409f-b766-d8766fcfdc59"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Failed to load model: [Errno 2] Unable to synchronously open file (unable to open file: name = 'your_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}